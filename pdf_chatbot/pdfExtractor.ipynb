{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa0263e-86a4-4003-b808-d2a9c8d5e56f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: odfpy in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: striprtf in c:\\users\\acer\\anaconda3\\lib\\site-packages (0.0.29)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\acer\\anaconda3\\lib\\site-packages (8.1.6)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\acer\\anaconda3\\lib\\site-packages (from odfpy) (0.7.1)\n",
      "Requirement already satisfied: click in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (8.26.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: decorator in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\acer\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install python-docx odfpy striprtf PyPDF2 nltk scikit-learn pandas ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010b2cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import docx\n",
    "import odf\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from docx import Document\n",
    "import PyPDF2\n",
    "\n",
    "# For ODT & RTF support\n",
    "from odf.opendocument import load\n",
    "from odf import text, teletype\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "# NLTK setup (download if needed)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "uploaded_files = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bc225e-acc9-4c64-9c2c-50b085473028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc10074e-41de-44e3-9b59-5d577bff3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "from extractor import pdf_Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73d0aff8-103d-4bb9-8f38-665cb99b1257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = tk.Tk()\n",
    "root.withdraw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ce97d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File selected: C:/Users/Acer/Downloads/EI_2022_IQSP-334_Abhinau-K_-Venkataramanan (1).pdf\n",
      "\n",
      "--- File Preview ---\n",
      "\n",
      "Assessing the Impact of Image Quality on Object-Detection Al-\n",
      "gorithms\n",
      "Abhinau K. Venkataramanan*, Marius Facktor*, Praful Gupta, and Alan C. Bovik;\n",
      "Department of Electrical and Computer Engineering,\n",
      "The University of Texas at Austin\n",
      "Abstract\n",
      "The field of image and video quality assessment has enjoyed\n",
      "rapid development over the last two decades. Several datasets\n",
      "and algorithms have been designed to understand the effects of\n",
      "common distortions on the subjective experiences of human ob-\n",
      "servers. The distortions present in these datasets may be synthetic\n",
      "(applying artificially computed blur, compression, noise, etc.) or\n",
      "authentic (in-capture lens flare, motion blur, under/overexposure,\n",
      "etc.). The goal of quality assessment is often to quantify the loss\n",
      "of visual “naturalness” caused by the distortion(s). We have re-\n",
      "cently created a new resource called LIVE-RoadImpairs, which\n",
      "is a novel image quality dataset consisting of authentically dis-\n",
      "torted images of roadways. We use the dataset to\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = pdf_Extractor.select_file()\n",
    "\n",
    "if file_path:\n",
    "    print(\"File selected:\", file_path)\n",
    "    result = pdf_Extractor.process_file(file_path)\n",
    "    if result:\n",
    "        print(\"\\n--- File Preview ---\\n\")\n",
    "        print(result[:1000])\n",
    "else:\n",
    "    print(\"No file selected.\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f16ccded-a779-439e-b2b1-07488c162e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Tokens\n",
      "0  [Assessing, Impact, Image, Quality, Object, De...\n",
      "            Token\n",
      "0       Assessing\n",
      "1          Impact\n",
      "2           Image\n",
      "3         Quality\n",
      "4          Object\n",
      "...           ...\n",
      "3991        Image\n",
      "3992      Quality\n",
      "3993       System\n",
      "3994  Performance\n",
      "3995          XIX\n",
      "\n",
      "[3996 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "if result:\n",
    "    \n",
    "\n",
    "    tokens = preprocess.tokenize_tokens(result)\n",
    "    lemmatized = preprocess.lemmatizing_tokens(tokens)\n",
    "    dfSentence = pd.DataFrame({'Tokens': [lemmatized]})\n",
    "    print(dfSentence)\n",
    "    tfidf_df, feature_names = preprocess.compute_tfidf(dfSentence, token_column='Tokens')\n",
    "    tfidf_df.head()\n",
    "    \n",
    "    df = pd.DataFrame(lemmatized, columns=[\"Token\"])\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72d82d-bc18-4cc7-97bf-ce007f27365c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a7b60-6af1-478d-91a2-dc2b5fafaab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
